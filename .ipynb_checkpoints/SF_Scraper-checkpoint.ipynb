{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import datetime\n",
    "\n",
    "import csv\n",
    "# Scraping items\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "import concurrent.futures\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "#from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SF_Urls','r') as f:\n",
    "    urls=pd.read_csv(f)\n",
    "urls2=[x.strip().strip('\\'').strip('\\'') for x in list(urls.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsf_template='https://trip.sftravel.com/plan-travel/united-states/san-francisco/?page={}'\n",
    "trip_sf_urls=[tripsf_template.format(i) for i in range(1,89)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(trip_sf_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_features={}\n",
    "for url in trip_sf_urls:\n",
    "    driver.get(url)\n",
    "    soup=BeautifulSoup(driver.page_source,'html.parser')\n",
    "    for location in soup.find_all('div',class_='items-item'):\n",
    "        try:\n",
    "            features=location.find(class_='items-item-category hidden-xs').text\n",
    "            name=location.find(class_='items-item-link').text\n",
    "            location_features[name]=features\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_dct(ta_to_sf):\n",
    "    ta_feature_dct={}\n",
    "    ta_places=list(ta_to_sf.keys())\n",
    "    for ta_place in ta_places:\n",
    "        ta_feature_dct[ta_place]=location_features[ta_to_sf[ta_place]]\n",
    "    return ta_feature_dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ta_feature_dct.pkl','wb') as f:\n",
    "    pkl.dump(ta_feature_dct,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('location_features.pkl','wb') as f:\n",
    "    pkl.dump(location_features,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urls2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(driver.page_source,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='data/SF_authors.pkl'\n",
    "with open(file,'rb') as f:\n",
    "    names=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=['https://www.tripadvisor.com/members/'+x for x in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urls[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tripadvisor.com/members/LauraT2211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.tripadvisor.com/members/Mismel2kl'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff=soup.find_all('li',class_='cs-review')\n",
    "type(stuff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stuff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8b37f38146e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattraction_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cs-review-location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mattraction_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stuff' is not defined"
     ]
    }
   ],
   "source": [
    "attraction_name=stuff[1].find_all(class_='cs-review-location')[0].text\n",
    "attraction_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=stuff[0].find_all(class_='cs-review-rating')[0].find('span')\n",
    "type(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    users={}\n",
    "    \n",
    "    name=url[36:]\n",
    "    driver.get(url)\n",
    "    soup=BeautifulSoup(driver.page_source,'html.parser')\n",
    "    reviews=soup.find_all('li',class_='cs-review')\n",
    "    ranks={}\n",
    "    for review in reviews:\n",
    "\n",
    "        try:\n",
    "            attraction_name=review.find_all(class_='cs-review-location')[0].text\n",
    "            rating=int([str(tag) for tag in review.find_all()][-3][-10:-9])\n",
    "        except:\n",
    "            pass\n",
    "        #rating=0\n",
    "        if 'San Francisco:' == attraction_name[:14]:\n",
    "            ranks[attraction_name]=rating\n",
    "    users[name]=ranks\n",
    "    return {name,ranks}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftrip_data=get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    well = [executor.submit(get_data, url) for url in urls[:10]]\n",
    "    counts.append(well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(urls):\n",
    "    count=0\n",
    "    tmp={}\n",
    "    users={}\n",
    "    for url in urls:\n",
    "        name=url[36:]\n",
    "        driver.get(url)\n",
    "        soup=BeautifulSoup(driver.page_source,'html.parser')\n",
    "        reviews=soup.find_all('li',class_='cs-review')\n",
    "        ranks={}\n",
    "        for review in reviews:\n",
    "\n",
    "            try:\n",
    "                attraction_name=review.find_all(class_='cs-review-location')[0].text\n",
    "                rating=int([str(tag) for tag in review.find_all()][-3][-10:-9])\n",
    "            except:\n",
    "                pass\n",
    "            #rating=0\n",
    "            if 'San Francisco:' == attraction_name[:14]:\n",
    "                ranks[attraction_name]=rating\n",
    "        users[name]=ranks\n",
    "        tmp[name]=ranks\n",
    "        count+=1\n",
    "        if count%100==0:\n",
    "            with open(f'data/file_{count}.pkl','wb') as f:\n",
    "                pkl.dump(tmp,f)\n",
    "            print(count)\n",
    "            tmp={}\n",
    "    \n",
    "    return users\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(users,ta_to_sf):\n",
    "    user_list=list(users.keys())\n",
    "    # Need full list of SF locations\n",
    "    places=[]\n",
    "    for user_key in users.keys():\n",
    "        for place in users[user_key].keys():\n",
    "            place=place[15:]\n",
    "            if place in list(ta_to_sf.keys()):\n",
    "                places.append(place)\n",
    "    places=list(set(places))\n",
    "\n",
    "\n",
    "    # Make array for user1\n",
    "    matrix=[]\n",
    "    for u in user_list:\n",
    "        user_likes=[]\n",
    "        for p in places:\n",
    "            if p in users[u].keys():\n",
    "                user_likes.append(users[u][p])\n",
    "            else:\n",
    "                user_likes.append(float('NaN'))\n",
    "        matrix.append(user_likes)\n",
    "\n",
    "    return np.array(matrix), user_list, places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for k in range(100,10000,100):\n",
    "    with open(f'data/file_{k}.pkl','rb') as f:\n",
    "        likes=pkl.load(f)\n",
    "        results.append(likes)\n",
    "        \n",
    "        \n",
    "res=results[0]\n",
    "for i in range(1,len(results)):\n",
    "    res={**res,**results[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, user_list, places = make_matrix(res,ta_to_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_clean=[x[15:] for x in places]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to reduce places_clean list\n",
    "def make_ta_to_sf(places_clean,sftrip_locations):\n",
    "    ta_to_sf={}\n",
    "    for pc in places_clean:\n",
    "        comp_best=0\n",
    "        current_closest=None\n",
    "        for sft in sftrip_locations:\n",
    "            comp=fuzz.partial_ratio(pc.lower(),sft.lower())\n",
    "            if comp>comp_best:\n",
    "                comp_best=comp\n",
    "                current_closest=sft\n",
    "\n",
    "        if comp_best>90:\n",
    "            ta_to_sf[pc]=current_closest\n",
    "    return ta_to_sf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ta_to_sf.pkl','wb') as f:\n",
    "    pkl.dump(ta_to_sf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftrip_locations=list(location_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('likes.pkl','wb') as f:\n",
    "    pkl.dump(np.array(matrix),f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
